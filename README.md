# Web-Crawler

note: may need to run /Applications/Python\ 3.6/Install\ Certificates.command

TODO:
- write report
- take user input of num pages and stop words
- finish crawler



crawler:
- url of each page
- outgoing links
- contents of title tag
- duplicate detection: "report if any urls refer to already seen content"
- broken links
- graphics (gif, jpg, jpeg, png)
- term-document frequency matrix
	- case insensitive matching
	- assign unique id to each doc
- 20 most common words


data structure:

